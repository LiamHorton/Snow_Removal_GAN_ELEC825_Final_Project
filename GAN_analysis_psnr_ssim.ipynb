{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NX1thx3LgXDx"
   },
   "outputs": [],
   "source": [
    "# Code based on souce from https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n",
    "\n",
    "# Required imports for dataset import, preprocessing and compression\n",
    "\n",
    "\"\"\"\n",
    "GAN analysis file. Takes in trained .h5 files created while training the network.\n",
    "Generates test files from testing synthetic input photos (files the GAN has never seen before).\n",
    "Generates psnr and ssim ratings for each model/.h5 files and loads the results into excel files.\n",
    "\"\"\"\n",
    "\n",
    "from os import listdir\n",
    "import numpy\n",
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "from numpy import savez_compressed\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy.random import randint\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import load_model\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FBbgGbJgXD3"
   },
   "outputs": [],
   "source": [
    "# Load images from a directory to memory\n",
    "def load_images(path, size=(256,256)):\n",
    "    pic_list = list()\n",
    "\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "\n",
    "    for filename in listdir(path):\n",
    "\n",
    "        # load and resize the image (the resizing is not being used in our implementation)\n",
    "        pixels = load_img(path + filename, target_size=size)\n",
    "\n",
    "        # convert to numpy array\n",
    "        pic_list.append(img_to_array(pixels))\n",
    "\n",
    "    return asarray(pic_list)\n",
    "\n",
    "# Load and prepare test or validation images from compressed image files to memory\n",
    "\n",
    "def load_numpy_images(filename):\n",
    "\n",
    "    # Load the compressed numpy array(s)\n",
    "    data = load(filename)\n",
    "\n",
    "    img_sets =[]\n",
    "\n",
    "    for item in data:\n",
    "        img_sets.append((data[item]- 127.5) / 127.5)\n",
    "\n",
    "    return img_sets\n",
    "\n",
    "# Plot source, generated and target images all in one output\n",
    "\n",
    "def plot_images(src_img, gen_img, tar_img):\n",
    "    images = vstack((src_img, gen_img, tar_img))\n",
    "    \n",
    "    # scale from [-1,1] to [0,1]\n",
    "    images = (images + 1) / 2.0\n",
    "\n",
    "    titles = ['Source', 'Generated', 'Expected']\n",
    "    # plot images row by row\n",
    "    for i in range(len(images)):\n",
    "        # define subplot\n",
    "        pyplot.subplot(1, 3, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(images[i])\n",
    "        # show title\n",
    "        pyplot.title(titles[i])\n",
    "    pyplot.show()\n",
    "\n",
    "# Load a single image\n",
    "def load_image(filename, size=(256,256)):\n",
    "    # load image with the preferred size\n",
    "    pixels = load_img(filename, target_size=size)\n",
    "    \n",
    "    # convert to numpy array\n",
    "    pixels = img_to_array(pixels)\n",
    "    \n",
    "    # scale from [0,255] to [-1,1]\n",
    "    pixels = (pixels - 127.5) / 127.5\n",
    "    \n",
    "    # reshape to 1 sample\n",
    "    pixels = expand_dims(pixels, 0)\n",
    "    \n",
    "    return pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyXEdBd7gXD5"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# Convert the training dataset to a compressed numpy array (NOT USED FOR METRICS)\n",
    "####################\n",
    "\n",
    "# Source images path (synthetic images)\n",
    "path = 'data/training/synthetic/'\n",
    "src_images = load_images(path)\n",
    "\n",
    "# Ground truth images path\n",
    "path = 'data/training/gt/'\n",
    "tar_images = load_images(path)\n",
    "\n",
    "# Perform a quick check on shape and sizes\n",
    "print('Loaded: ', src_images.shape, tar_images.shape)\n",
    "\n",
    "# Save as a compressed numpy array\n",
    "filename = 'data/training/train_256.npz'\n",
    "savez_compressed(filename, src_images, tar_images)\n",
    "print('Saved dataset: ', filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPUgmx-qgXD6"
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# Convert the validation dataset to a compressed numpy array (.npz)\n",
    "###################\n",
    "\n",
    "# Source images path\n",
    "path = 'data/validation/synthetic/'\n",
    "src_images = load_images(path)\n",
    "\n",
    "# Ground truth images path\n",
    "path = 'data/validation/gt/'\n",
    "tar_images = load_images(path)\n",
    "\n",
    "# Perform a quick check on shape and sizes\n",
    "print('Loaded: ', src_images.shape, tar_images.shape)\n",
    "\n",
    "# Save as a compressed numpy array\n",
    "filename = 'data/validation/validation_256.npz'\n",
    "savez_compressed(filename, src_images, tar_images)\n",
    "print('Saved dataset: ', filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dOzanAMgXD7"
   },
   "outputs": [],
   "source": [
    "# Load the validation dataset from the compressed numpy array to memory\n",
    "\n",
    "img_sets = load_numpy_images('data/validation/validation_256.npz')\n",
    "src_images = img_sets[0]\n",
    "print('Loaded: ', src_images.shape)\n",
    "\n",
    "#tar_images = img_sets[1]\n",
    "#print('Loaded: ', tar_images.shape)\n",
    "\n",
    "# Gain some memory\n",
    "del img_sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muUiFS4zgXD8"
   },
   "outputs": [],
   "source": [
    "# Get the list of gt image names so outputs can be named correctly\n",
    "path = 'data/validation/gt/'\n",
    "img_list = os.listdir(path)\n",
    "\n",
    "exp_path = 'models/exp6/'\n",
    "model_list = os.listdir(exp_path)\n",
    "\n",
    "# loop through model/.h5 files \n",
    "for model in model_list:\n",
    "    model_dir = 'outputs/'+model[:-3]\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "    # load model weights to be used in the generator\n",
    "    predictor = load_model(exp_path+model)\n",
    "    names = 0\n",
    "\n",
    "    for i in range(0, len(src_images),10 ):\n",
    "        # push image through generator\n",
    "        gen_images = predictor.predict(src_images[i:i+10])\n",
    "        \n",
    "        # name and export file\n",
    "        for img in range(len(gen_images)):\n",
    "            filename = model_dir+'/'+img_list[names]\n",
    "            names += 1\n",
    "            matplotlib.image.imsave(filename, (gen_images[img]+1)/2.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXxlxPmygXD9"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate generated images from each model run for PNSR and SSIM\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "exp_dir = 'outputs/' # result director\n",
    "gt_dir = 'data/validation/gt/' # ground truth directory\n",
    "img_list = os.listdir(gt_dir)\n",
    "\n",
    "column_names =[]\n",
    "exp_list = [ f.name for f in os.scandir(exp_dir) if f.is_dir() ]\n",
    "for exp in exp_list:\n",
    "\n",
    "    model_list = [ f.name for f in os.scandir('outputs/'+exp+'/') if f.is_dir() ]\n",
    "    \n",
    "    for model in model_list:\n",
    "            column_names.append(exp+'_'+model)\n",
    "# create data frames for excel output\n",
    "psnr_df = pd.DataFrame(columns = column_names)\n",
    "ssim_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "i=0\n",
    "psnr_master=[]\n",
    "ssim_master=[]\n",
    "for img in img_list:  # loop through every image created by the generator\n",
    "    i+=1\n",
    "    # load image and create a grayscale for ssim measurement\n",
    "    gt = cv2.imread(gt_dir+img)\n",
    "    gt_gray = cv2.cvtColor(gt, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    psnr_list=[]\n",
    "    ssim_list =[]\n",
    "\n",
    "    exp_list = [f.name for f in os.scandir(exp_dir) if f.is_dir()]\n",
    "    # for each experiment\n",
    "    for exp in exp_list:\n",
    "        \n",
    "        model_list = [ f.name for f in os.scandir('outputs/'+exp+'/') if f.is_dir() ]\n",
    "        # for each generator weights/model (outputted h5 file from experiemnt)\n",
    "        for model in model_list:\n",
    "            pred = cv2.imread(exp_dir+exp+'/'+model+'/'+img)\n",
    "            pred_gray = cv2.cvtColor(pred, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # calculate psnr and ssim\n",
    "            psnr_list.append(psnr(gt, pred, data_range=pred.max() - pred.min()))\n",
    "            ssim_list.append(ssim(gt_gray, pred_gray, data_range=pred.max() - pred.min()))\n",
    "            \n",
    "\n",
    "    psnr_master.append(psnr_list)\n",
    "    ssim_master.append(ssim_list)\n",
    "\n",
    "# export for excel use   \n",
    "psnr_df = pd.DataFrame(psnr_master, columns = column_names)\n",
    "psnr_df.index = img_list\n",
    "psnr_df.to_csv(\"PSNR.csv\")\n",
    "\n",
    "ssim_df = pd.DataFrame(ssim_master, columns = column_names)\n",
    "ssim_df.index = img_list\n",
    "ssim_df.to_csv(\"SSIM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wm3QW5N4gXD-"
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "\n",
    "['sidewalk winter -grayscale -gray_05189.jpg', 'sidewalk winter -grayscale -gray_07146.jpg', 'snow_animal_00447.jpg', 'snow_animal_03742.jpg', 'snow_intersection_00058.jpg', 'snow_nature_1_105698.jpg','snow_nature_1_108122.jpg','snow_nature_1_108523.jpg','snow_walk_00080.jpg','winter intersection -snow_00399.jpg','winter__street_03783.jpg','winter__street_05208.jpg']\n",
    "pic_list_dims = [(426, 640), (538, 640), (640, 427), (432, 640), (480, 640), (640, 527), (480, 640), (427, 640), (640, 427), (502, 640), (269, 640), (427, 640)]\n",
    "\n",
    "i=0\n",
    "\n",
    "# load an image\n",
    "def load_image(filename, size=(256,256)):\n",
    "\t# load image with the preferred size\n",
    "\tpixels = load_img(filename, target_size=size)\n",
    "\t# convert to numpy array\n",
    "\tpixels = img_to_array(pixels)\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tpixels = (pixels - 127.5) / 127.5\n",
    "\t# reshape to 1 sample\n",
    "\tpixels = expand_dims(pixels, 0)\n",
    "\treturn pixels\n",
    "\n",
    "src_path = 'data/realistic_full/'\n",
    "src_filename = pic_list[i]\n",
    "src_image = load_image(src_path+src_filename)\n",
    "\n",
    "print('Loaded', src_image.shape)\n",
    "\n",
    "model_path = 'models/Experiment4/'\n",
    "model_filename = 'model_125000.h5'\n",
    "\n",
    "predictor = load_model(model_path+model_filename)\n",
    "gen_img = predictor.predict(src_image)\n",
    "\n",
    "# scale from [-1,1] to [0,1]\n",
    "gen_img = (gen_img[0] + 1) / 2.0\n",
    "# plot the image\n",
    "pyplot.imshow(gen_img)\n",
    "pyplot.axis('off')\n",
    "pyplot.show()\n",
    "\n",
    "gen_path = 'final/'\n",
    "gen_filename = src_filename\n",
    "\n",
    "matplotlib.image.imsave(gen_path+gen_filename, gen_img)\n",
    "gen_img = load_img(gen_path+gen_filename, target_size=pic_list_dims[i])\n",
    "pyplot.imshow(gen_img)\n",
    "pyplot.axis('off')\n",
    "pyplot.show()\n",
    "print(gen_img)\n",
    "gen_img.save(gen_path+gen_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsv99hkJgXD_"
   },
   "outputs": [],
   "source": [
    "pic_list = ['sidewalk winter -grayscale -gray_05189.jpg', 'sidewalk winter -grayscale -gray_07146.jpg', 'snow_animal_00447.jpg', 'snow_animal_03742.jpg', 'snow_intersection_00058.jpg', 'snow_nature_1_105698.jpg','snow_nature_1_108122.jpg','snow_nature_1_108523.jpg','snow_walk_00080.jpg','winter intersection -snow_00399.jpg','winter__street_03783.jpg','winter__street_05208.jpg']\n",
    "src_path = 'data/realistic_full/'\n",
    "\n",
    "dims=[]\n",
    "for img in pic_list:\n",
    "    pixels = load_img(src_path+img)\n",
    "    dims.append(tuple(reversed(pixels.size)))\n",
    "print(dims)   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56392c96040e3bcb1df9bb86721eded46c20484ed0f220afd8459307bafd62b8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('825_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4.0,
  "colab": {
   "name": "assess_models (1).ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
